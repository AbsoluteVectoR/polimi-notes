# MIPS Processor Pipelining and Hazards

The whole first part of the course would be instruction level parallelism.

Of course, there is a lot of complexity in that regard.

But the basic concept for having ILP is that you have a pipeline.

And I might have multiple instructions working independently.

And if I have multiple instructions, I can have that the whole pipeline is operating at the same time on different instructions.

So I can have, if I have four stations, I suppose, I can have at most four instructions that are fulfilling the pipeline.

ISA = Instruction Set Architecture

MIPS ISA is also another important feature, is that it is a fixed length ISA.

Which means that all the instructions have the same length.

![](images/69d0cecc684880b6681bef2d4d00f7bb.png)

Is this the same for every kind of ISA?
ARM like MIPS, it's a fixed length.
It's a RISC architecture.

Which means that ARM tries to have that each operation takes one clock cycle.
So it's closely related to MIPS.

Do you know another ISA which is not like this? X86.

It's X86, which is a CISC ISA.

X86 has fields that say the next part of the instruction will be a certain amount of bytes.

Internally, it becomes RISC, but our code is CISC.

The other huge part of an architecture...
Broadly speaking, in an architecture, you have a certain part that operates on data, which is called the data path.

And then you have the control path.

Control path is instead the one that controls the operation.

So how does those operations work and when those operations have to start, how can I handle the instruction level parallelism? The controller is a part that is not very much considered, but it's something that makes a real difference in an architecture.

Because you can exploit and take advantage of a certain component if you have a good controller.

![](images/c52ea84bb2669e9ec83c00427fa88b37.png)

And in a CPU, it's a part that really limits or pushes the performance of a CPU.

Looking at a different perspective, here is how the MIPS data path appears.

![](images/cedb47304826bac5a8e217bce5eadc6b.png)

In a multi-stage pipeline, the first stage is instruction fetch, where instructions are retrieved. The next stage is decode, which determines what operations the instructions entail and sets up the CPU to perform those computations. The execution phase follows, where arithmetic logic operations take place. The memory stage accesses main memory or cache hierarchy. Lastly, the result of the computation is written back to the register file.

And what is your best friend? It would be this timing diagram, where we can really see what is ILP.

![](images/927eef83c3c44d320caa7360488b8cac.png)

Theoretically speaking, at cycle 5, we have that four stages of our pipeline are all busy.

We do have three kinds of hazards.

Structural Hazards: Attempt to use the same resource from different instructions simultaneously Example: Single memory for instructions and data

Data Hazards: Attempt to use a result before it is ready Example: Instruction depending on a result of a previous instruction still in the pipeline

Control Hazards: Attempt to make a decision on the next instruction to execute before the condition is evaluated Example: Conditional branch execution


Instruction Level Parallelism

Parallelism with simple tecnique. But since it's simple, three hazards:

* **Structural Hazards**: Attempt to use the same resource from different instructions simultaneously. Example: Single memory for instructions and data
* **Data Hazards**: Attempt to use a result before it is ready. Example: Instruction depending on a result of a previous instruction still in the pipeline
* **Control Hazards**: Attempt to make a decision on the next instruction to execute before the condition is evaluated Example: Conditional branch execution

$$\text{Pipeline Speedup} = \frac{\text{Pipeline Depth}}{\text{1 + Pipe Stall Cycles per Instruction due to Branches}}$$

$$\text{Pipeline Speedup} = \frac{\text{Pipeline Depth}}{\text{1 + Branch Frequency \* Branch Penalty}}$$

To feed the pipeline we need to fetch a new instruction at each clock cycle, but the branch decision (to change or not change the PC) is taken during the MEM stage. This delay to determine the correct instruction to fetch is called Control Hazard or Conditional Branch Hazard If a branch changes the PC to its target address, it is a taken branch If a branch falls through, it is not taken or untaken.

* Without forwarding: To stall the pipeline until the branch decision is taken (stalling until resolution) and then fetch the correct instruction flow.

![](images/65aabdb2c663857d577615e38d3b33ff.png){width=50%}

With forwarding, to reduce stalling time.

![](images/4b078bcea8b91ccf02500541ec99c9de.png){width=50%}

Early Evaluation of the Program Counter PC. Update the PC register
as soon as possible in the pipeline during ID stage. Move a sort of controller of the branch outcome before the execute stage, inside the decode stage.

With the branch decision made during ID stage, there is a reduction of the cost associated with each branch (branch penalty): We need only one-clock-cycle stall after each branch Or a flush of only one instruction following the branch

One-cycle-delay for every branch still yields a performance loss of 10% to 30% depending on the branch frequency

![](images/f3ce2f23d45cff41ab065f23a8753818.png){width=50%}

But note that this has an "issue".. anticipating the evaluation of the PC has its 'cons'.
![](images/8dd1cca3a5dbd7c0b23599e2e07f1e01.png){width=50%}


Recall MIPS with forwarding

* EX/EX path
* MEM/EX path
* MEM/MEM path

In principle EX/ID is not needed since what it's computed in EX is not useful in ID stage. But if there is early branch evaluation it might be useful.
