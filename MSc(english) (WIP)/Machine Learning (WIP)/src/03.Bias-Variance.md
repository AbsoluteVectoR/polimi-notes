# Bias-Variance

Is the loss function a good way to evaluate a model?
No, the loss function is only telling us how good the model is on the data used to train the model. But it's telling nothing about unseen data. 
Supervised learning is not used to explain seen data! 

Bias-Variance Decomposition

The Bias-Variance is a framework to analyze the performance of models.

We can decompose the expected square error (which indicates the performance of a model) as:

$$
\begin{aligned}
\mathbb{E}\left[(t-y(\mathbf{x}))^2\right] & =\mathbb{E}\left[t^2+y(\mathbf{x})^2-2 t y(\mathbf{x})\right] \\
& =\mathbb{E}\left[t^2\right]+\mathbb{E}\left[y(\mathbf{x})^2\right]-\mathbb{E}[2 \operatorname{tr}(\mathbf{x})] \\
& =\mathbb{E}\left[t^2\right] \pm \mathbb{E}[t]^2+\mathbb{E}\left[y(\mathbf{x})^2\right] \pm \mathbb{E}[y(\mathbf{x})]^2-2 f(\mathbf{x}) \mathbb{E}[y(\mathbf{x})] \\
& =\operatorname{Var}[t]+\mathbb{E}[t]^2+\operatorname{Var}[y(\mathbf{x})]+\mathbb{E}[y(\mathbf{x})]^2-2 f(\mathbf{x}) \mathbb{E}[y(\mathbf{x})] \\
& =\operatorname{Var}[t]+\operatorname{Var}[y(\mathbf{x})]+(f(\mathbf{x})-\mathbb{E}[y(\mathbf{x})])^2 \\
& =\underbrace{\operatorname{Var}[t]}_{\sigma^2}+\underbrace{\operatorname{Var}[y(\mathbf{x})]}_{\text {Variance }}+\underbrace{\mathbb{E}[f(\mathbf{x})-y(\mathbf{x})]^2}_{\text {Bias}^2}
\end{aligned}
$$


$\sigma^2$ is also called **Irreducible error** while the **reducible error** is composed by the other components ... so the variance and the bias squared.


Visualization: 

![](c335c1050b5f93c3cd36bf594f9cf3c7.png){width=50%}


Typically there is a trade-off between bias-variance:

- bias measures the difference between truth and what we expect to learn
- variance measures the difference between each model learned from a particular dataset and what we expect to learn


The more complex is the model and the higher will be the variance: 

![](dcd091ba409e0c0ac14cf1dd694cfb16.png){width=50%}

## Exercitation

![](images/Pasted%20image%2020230331203744.png)

This is parameter space. On the left 100 points in the dataset, on the right 10k points.  Each point rapresent a vector of parameters. On the left we have an higher variance. 

Informally 
The variance of the  model in ML is how much it varies as the function of dataset.

**Summary:** The variance of the ML model indicates how much it changes according to the dataset used.

Models too much complex -> minimum training error -> but overfitting. 


Training error is the worst way to select among more models. 

Using different dataset is crucial to have independent datasets and to evaluate the quality of the model. 

![](images/Pasted%20image%2020230331205413.png)

The U-shaped curve is a common shape for the test error when plotted against model complexity in machine learning.
Underfitting is when a model is too simple and doesn't capture the complexity of the data. Overfitting is when a model is too complex and fits the noise in the data. The desired number of parameters is the balance between the two extremes, where the model performs well on both the training and testing data.

The validation dataset is used to select the best model among multiple ones. This is done by computing a validation on a different dataset (validation set). But this dataset has a finite number of points, making it not ideal for also assessing model quality. Therefore, three datasets are used: training, validation, and test. The training and validation datasets are used to select the best model, while the test dataset is independent and is used to evaluate the final model's performance. It is important to separate these three datasets to avoid creating statistical dependency.

There are others adjustment techniques (23-03-2023 exe)

$$
\begin{aligned}
& C_p=\frac{1}{N}(R S S+2 d \tilde{\sigma}) \\
& A I C=-2 \log L+2 d \\
& B I C=\frac{1}{N}(R S S+\log (N) d \tilde{\sigma}) \\
& \quad R^2 R_{a d}^2=1-\frac{R S S /(N-d-1)}{T S S /(N-1)}
\end{aligned}
$$


While you fit a Linear Model to your data set. You are thinking about changing the Linear Model to a Quadratic one (i.e., a Linear Model with quadratic features Ï•(x) = [1, x, x2 ]). Which of the following is most likely true: 

Using the Quadratic Model will decrease your Irreducible Error; FALSE the irreducible error is irreducible .. it's irrelevant the model used. 


If $H_1$ is a smaller subset of $H_2$:

- the bias of $H_2$ will be smaller than the bias of $H_1$.
- the variance of $H_1$ is smaller than that of $H_2$. 

It's always a good thing increase the number of samples, since it decreases the variance of the model and therefore the reducible error: since it is composed by the sum of the squared bias (which is fixed and doesn't change by increasing the number of samples) and the variance (which is decrease). 

---

I have to study why: 

We estimate the regression coefficients in a linear regression model by minimizing ridge regression for a particular value of $\lambda$. For each of the following, describe the behaviour of the following elements as we increase $\lambda$ from $0$ (e.g., remains constant, increases, decreases, increase and then decrease

![](images/Pasted%20image%2020230331213430.png)

As always there is a tradeoff between **variance** and **squared bias**. 

