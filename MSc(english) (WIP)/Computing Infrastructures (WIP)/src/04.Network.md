

![](images/0a72a8f21a39559160832ca72318c418.png)

Lesson with (Maier)

Some context: 

- In the early days of computing, computers weren't connected in a network.
- Eventually, networking protocols were developed and the most widely used one is TCP/IP.
- The evolution of computing infrastructures can be presented in the following steps: client-server, web applications, microservices and datacenters/warehouse scale computing. 
- In terms of horizontal scaling, networking lacks a straightforward solution. 
- Increasing the leaf bandwidth is simple: doubling the number of servers will provide twice the network ports and bandwidth. 
- However, if every server needs to communicate with the others, **bisection bandwidth** must be considered. 


## Bisection bandwidth 

Bisection bandwidth is the bandwidth across the narrowest line that divides the cluster into two parts equally, and it is important for characterizing the network capacity.

![](images/a6a1250b7866c595bd53bf0f4e3f3f5c.png)

Data center's networking can be classified in the following ways: 

- **Switch-centric** (also called router-centric): alle the nodes are implemented as specialized hardware which can manage traffic performing packet forwarding.
- **Server-centric**: Uses servers with multiple Network Interface Cards (NICs) to act as switches in addition to performing other computational functions. This approach might cause slow performance.
- **Hybrid architectures**: combining switches and servers for packet forwarding is a current trend in computing infrastructures, but it can be expensive. 




![](images/78faa46fe5601b0bd947436844d1b133.png)

East-West traffic is generally bigger than North-South traffic. Some examples: 

- Cloud storage requires at least 3 copies of the same data for resilience, usually 2 in the same rack and 1 in another rack. 
- VM migration. 
- Network Function Virtualization (NFV): Data may be processed through a sequence of VMs such as firewall, web server, parental control, accounting server.

Examples of east-west traffic: 

- **Unicast**: point to point (VM migration, data backup, stream data processing)
- **Multicast**: one-to-many (software update, data replication for reliability, OS image provision for VM)
- **Incast**: many-to-one communication (reduce phase in MapReduce, merging tables in databases)

# Switch-centric


## Switch-centric: Classical 3-tier architecture


![](images/99c44299a39fd8b7b4d0026c4c484de1.png)

![](images/e08bfa0f814fd3f96554e7b70e0a7a03.png)

Three layer architecture reflects the topology of the data center.

![](images/ce9644a1496d5d35b5d4c09e02ab2f52.png)

Typically approach to networking in a generic rack: in a rack, all servers are connected to a ToR access switch. the servers and the ToR switch are colocated in the same rack

![](images/121bb5fac22a7cdad8a38cbb2d559b1a.png){width=50%}

Aggregation switches are either in dedicated racks or shared racks with other Top-of-Rack (ToR) switches and servers. This setup has limited scalability and can lead to higher complexity for switch management.

![](images/90c0c80aeff838e4e31608dab44f0325.png){width=50%}

End-of-Row (EoR) is an alternative to Top-of-Rack (ToR) where an aggregation switch is placed at the end of a line of racks, one per corridor. Servers in one rack are directly connected to the aggregation switch in another rack. However, EoR requires aggregation switches with more ports and complex cabling, resulting in longer cables and higher costs.

![](images/fca19db5031df1f11e2c99f849792be9.png){width=50%}

The solution is simple, but it can be costly for large data centers due to the need for faster network equipment in upper layers. For example: if 1 GB Ethernet is required at the access layer, 10 GB Ethernet at the aggregation layer, and 25 GB optical connections at the core layer. As a result, the cost of acquisition and energy consumption can be very high.

Switch-centric architectures:

- Classical 3-tier architecture
- Leaf-Spine architectures



## Switch-centric: Leaf-Spine architectures


It's an architecture based on two-stage interconnections based on a circuit switching architecture, once used in telephony (an alternative architecture to the "classical" packet switching). There are two levels:

- **Leaf** switches act as top-of-rack (ToR) switches  
- **Spine** switches are dedicated aggregation switches.

![](images/6881ad700b7fc1cd794da7d22be84759.png)

- Leaf and spine topology is bidirectional for each switching module.
- **Clos** design has advantages such as using homogeneous equipment and routing as the fundamental interconnect model. 
- Number of hops is the same for any pair of nodes
- Small blast radius: if you have a failure in the architecture, the blast (the number of interested machines) is limited.

pod 

- Add a super-spine tier for a scalable and cost-efficient architecture with maximum bisection bandwidth.
- Point Of Delivery (POD): a group of several components that work together to deliver network services. It enhances modularity, scalability, and manageability of data.
- Gigabit Ethernet switches with the same number of ports can be used.

![](images/1906714cfb66f03d300f8723052addf8.png)

This architecture is known to be used by Microsoft and Amazon for example..

![](images/7cc2aaf3787e14b8084547ebf1e02aac.png)


## Switch-centric: Google's case


- Google's design approach for their computing infrastructures: multistage Clos topologies. Their control is centralized, with one configuration pushed to all switches. They design their hardware to be modular, with simple and robust software.

![](images/54f68e4451a9a26e5e82d6467417aa53.png)

![](images/0b34528425e254b62509948727792823.png){width=50%}

# Server-centric 

- A server-centric architecture proposed for container-sized data centers.
- Only servers used to build the data center, reducing costs.
- 3D-Torus topology used for direct server interconnection.
- Network locality exploited to increase communication efficiency.
- Drawbacks are servers requiring multiple NICs, long paths, and high routing complexity.

## Hybrid architectures 



![](images/015593df3780bfe403a95cffd03a93bf.png)




