# Storage

SSD good for random reads but issues with random writes. 

HDD always more used in datacenters. 

often storage is a bottleneck


Disks can be seen by an OS as a collection of  
data blocks that can be read or written independently. 

- To allow the ordering/management among them, each block is characterized by a unique numerical address called LBA (Logical Block Address). 
- Typically, the OS groups blocks into clusters to simplify the access to the disk. Clusters, which can range from 1 disk sector (512 B) to 128 sectors (64 KB), are the minimal unit that an OS can read from or write to a disk. 

Clusters contains: 

- File data
- Meta data:
	- File names  
	- Directory structures and symbolic links  
	- File size and file type  
	- Creation, modification, last access dates  
	- Security information (owners, access list, encryption)  
	- Links to the LBA where the file content can be located on the disk

Since the file system can only access clusters, the real occupation of space on a disk for a file is always a multiple of the cluster size.

$$\text{actual size on disk}= ceil (\frac{\text{the file size}}{\text{the cluster size}})*\text{the cluster size}$$

The waste of space is called internal fragmentation of files.
$$\text{waste disk space} = \text{actual size on disk} - \text{file size}$$

Deleting a file never actually deletes the data on the disk: when a new file will be written on the same clusters, the old data will be replaced by the new one.

As the life of the disk evolves, there might not be enough space to store a file contiguously. In this case, the file is split into smaller chunks that are inserted into the free clusters spread over the disk. The effect of splitting a file into non-contiguous clusters is called external fragmentation. As we will see, this can reduce a lot the performance of an HDD.

HDD 

An HDD consists of one or more rigid ("hard") rotating disks (platters) with magnetic heads arranged on a moving actuator arm to read and write data to the surfaces.

![](1e50e0915030e7f00687f44530fa2b4b.png)

Drive geometry  
§ Sectors arranged into tracks  
§ A cylinder is a particular track on multiple platters  
§ Tracks arranged in concentric circles on platters  
§ A disk may have multiple, double-sided platters

To understand well this: 

Externally, hard drives expose a large number of sectors (blocks)  
§ Typically 512 or 4096 bytes  
§ Individual sector writes are atomic  
§ Have a header and an error correction code  
§ Multiple sectors writes may be interrupted (torn write)


![](cbad625a261fa6267408a654f3b3c385.png){width = 50%}

The external track are "faster" to read since angular velocity considerations and are more dense. 

Four types of delay:

1. Rotational Delay :Time to rotate the desired sector to the read head related to RPM 2 $T_{rotation}=\frac{R_{period}}{2}$ with $R_{period}=\frac{1}{RPM}$
2. Seek delay: Time to move the read head to a different track $T_{\text{seek AVG}}=\frac{T_{\text{seek MAX}}}{3}$ 
3. Transfer time: average time for a request (write or read). The seek time rapresents the time necessary to align the head over the track, then there is the time where the sector is waited to be under the head (and it's based on rotational speeds ... just an estimation), then there is the time given by the controller to transfer data, later there is an overhead. So at the end:$T_{I/O}=T_{seek}+T_{rotation}+T_{transfer}+T_{overhead}$. Or, considering data locality: $T_{I/O}=(1-DL)(T_{seek}+T_{rotation})+T_{transfer}+T_{overhead}$.
4. Controller Overhead: Overhead for the request management



Data locality 


--- 


HDD optimized for sequentials read


Disk Scheduling

Since there is a queue of requests to the disk, they can be reordered to improve performance. Several scheduling algorithms: 

- First come, first serve (FCFC): Most basic scheduler, serve requests in order ![](710021e370d6c199538d20f59ad5ec76.png){width = 50%}
- Shortest seek time first (SSTF): Minimize seek time by always selecting the block with the shortest seek time  
- SCAN (the elevator algorithm): Head sweeps across the disk servicing requests in order.![](a25f15a279c0ff9f23eccc2dd98d1dc6.png){width=50%} 
- C-SCAN (circular scan), C-LOOK: variants of Scan 


On-disk scheduling  
- Disk knows the exact position of the head and platters  
- Can implement more advanced schedulers  
- But, requires specialized hardware and drivers


# SSD 

![](7f8c1361b02655a2a7d01c2157b9ff8e.png){width=50%}

- Single-level cell (SLC): simplest solution. For each cell just a voltage. Single bit per cell.
- Multi-level cell (MLC): Two bits per cell
- Triple-level cell (TLC): three bits per cel
- QLC, PLC...

![](9aa231b54f0510d41c9d740e737344b1.png){width=50%}

NAND flash is organized into Pages and Blocks:

- A page contains multiple logical block (e.g. 512B-4KB) addresses (LBAs)
	- A block typically consists of multiple pages (e.g. 64) with a total capacity of around 128-256KB. Pages can be in three states:  
		- Empty or erased
		- dirty or invalid
		- in use or valid

Actually there are some constraints: 

Pages: smallest unit that can be read/written BUT Blocks (or Erase Block): smallest unit that can be erased

Only dirty pages can be erased, but this must be done at the block  
level (all the pages in the block must be dirty or empty)

Only empty pages can be written

Remark: we can write and read a single page of data from a SSD but we have to delete an entire block to release it

This is because of the way that NAND flash memory works. Each page within a block can only be erased and rewritten a certain number of times before it becomes unreliable. Therefore, SSDs use a technique called wear leveling to evenly distribute writes and erases across all of the blocks in the drive, which helps to prolong the lifespan of the drive.

This means that the entire block cannot be erased and rewritten until all of the pages within the block are no longer in use. To ensure that all of the pages within a block are no longer in use, the SSD must move any valid data from the other pages within the block to a different block before the entire block can be erased.





breakdown of the oxide layer within the floating-gate transistors of NAND flash memory. The erasing process hits the flash cell with a relatively large charge of electrical energy. 

Each time a block is erased, the large electrical charge  
actually degrades the silicon  
material


![](4ebde75a612141acb9c6898e68d62f50.png){width=50%}

Flash Translation Layer (FTL) is an SSD component that make the SSD “look as HDD”

- Data Allocation and Address translation: Efficient to reduce Write Amplification effects and Program pages within an erased block in orde
- Garbage collection: reuse of pages with old data
- Wear leveling: should try to spread writes across the blocks of the flash ensuring that all of the blocks

![](Pasted%20image%2020230318153934.png){width=50%}

Garbage collection is expensive
and also 
Problem: most file systems don’t actually delete data § E.g. On Linux, the “delete” function is unlink() and it removes the file meta-data, but not the file itself so the GC wastes effort copying useless pages. But a solution of this is: OS support for TRIM

Also Mapping Table Size is a problem ... With a 1TB SSD with a 4byte entry per 4KB page, 1GB of DRAM is needed for mapping.

Some approaches to reduce the costs of mapping:

- Block-based mapping: Mapping at block granularity, to reduce the size of a mapping table.
- Hybrid mapping: When looking for a particular logical block, the ftl will consult the page mapping table and block mapping table in order.
- Page mapping plus caching: cache the active part of the page-mapped FTL.