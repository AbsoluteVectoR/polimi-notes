[05.Grammatiche Formali](../../../BSc(italian)/Algoritmi%20e%20Principi%20dell'Informatica/src/05.Grammatiche%20Formali.md) 

A context-free grammar is said to be "free" because the production rules apply equally to all occurrences of a nonterminal symbol in the grammar, without regard to the context in which it appears. This distinguishes it from a context-sensitive grammar, where the production rules depend on the context in which the nonterminal appears.


A generative grammar, also known as syntax, is a set of simple rules that can be repeatedly applied to generate valid strings. The grammar defines languages through rule rewriting and the repeated application of these rules. Rules can be classified based on their form, and an axiom (typically represented by the symbol S) is used to start the derivation process and is the only non-terminal symbol that can be used as the left part of a rule. Typically, terminal characters are represented by lowercase Latin letters, while nonterminal characters are represented by uppercase Latin letters. Strings containing only terminal characters are also represented by lowercase Latin letters, while strings containing only non-terminal characters are represented by Greek lowercase letters. Strings containing both terminal and non-terminal characters are represented by Greek lowercase letters. Finally, a rule that is both left recursive and right recursive is called left-right-recursive or two-side-recur.




````
<EXPR> --> <IMP> [imp <IMP>]
<IMP> --> <TRM> (or <TRM> )*
<TRM> --> <FCT> (and <FCT>)*
<FCT> --> [not] <EQU>
<EQU> --> <OBJ> ['=' <OBJ> ]
<OBJ> --> id | '(' <EXPR> ')' 
````

The grammar is simple and generally uses EBNF rules. 

In order to generate a left-associative operator in a grammar, it is necessary to use left-recursive rules.
````
A -> A terminal | X 
````


What is a BNF grammar? 

The focus is on grammars with regular expressions in the right parts of their rules, known as extended context-free form (EBNF).

# Free grammars

Regular expressions can provide lists but not nesting (recursion). 
 $$G =<V,\Sigma,P,S>$$
 where:
 - $V$ is the set of non terminals symbols
 - $\Sigma$ is the set of terminals symbols
 - $P$ is the set of productions 
 - $S$ is the axiom, a particular symbol of $V$ 


Recursion is the key to create infinite grammars. The necessary and sufficient condition for a grammar to be infinite is that there is a recursive derivation. Note that a grammar have a recursive derivations iff the corrisponding graph has a circuit. 

Clean grammars are grammars without a circular axioms. 

### Syntax tree



Given a grammar $G$ and a string in $L(G)$ we can build a syntax tree of the string where the root is the axiom $S$, the leafs are the sequence of the symbols of the string and all the branches are the productions used to generate the string. 


Two possible algorithms to build syntax trees: 

- ELL: top-bottom 
- ELR: bottom-up 

## Ambiguity 


With the definition of Syntax Tree we can also specify what is an ambiguity in the context of grammars.
A sentence is ambiguous if it admits different syntax trees. The number of distinct trees is also the degree of the ambiguity.

> Avoid the ambiguity in the grammar design phase. 

Ambiguity can be caused by bilateral recursion

Not decidable. Ambiguity if more than one syntactic tree. 

They use different rules. do not confuse it with the order in which the rules apply.


# Grammar classification 

In this course, we will only be dealing with type 2 and 3 grammars.

-   Chomsky's classification
-   Chomsky proposed a classification of grammars, thus establishing an order based on their generality and defining the "types" from 0 to 3, where type 3 represents the least general grammars and type 0 is the most general case.
-   Type 0 grammars: family of recursively enumerable languages
    -   Associated with Touring machines and generates recursively enumerable languages. The languages generated are not generally decidable.
    -   Rules are of the most general type:
-   Type 1 grammars: family of context-sensitive languages
    -   Associated with Touring machines with tape of length equal to that of the string to be recognized. Generates context-sensitive languages, which are always decidable.
    -   Rules are of the type:
-   Type 2 grammars: family of unrestricted languages
    -   Associated with non-deterministic stack automata. Generates unrestricted languages, which are always decidable and which we have already extensively analyzed. These are unrestricted grammars, whose rules are of the type:
-   Type 3 grammars: family of regular languages
    -   Associated with finite-state automata. Generates regular languages. These are therefore unilinear grammars (right or left), whose rules are of the type:
        -   If the grammar is unilinear to the right:
        -   If the grammar is unilinear to the left:
-   Observation:
    -   The families of grammars are linked by a strict containment relationship:
        -   All type 3 grammars are also type 2, type 1 and type 0.
        -   All type 2 grammars are also type 1 and type 0.
        -   All type 1 grammars are also type 0.



|Grammar  | Rule type | Language Family| Recognizer Model |  
|:---:|:---:|:---:|:---:|
| Type 2 | $A \rightarrow \alpha$ with $A$ non-terminal and $\alpha$ can be anything (non-terminal/terminal)  |context-free lang / BNF lang| Pushdown Automaton (non-deterministic) |
| Type 3 | $A \rightarrow uB$ or $A \rightarrow Bu$ (not both) with $A$ non-terminal and B nonterm or $\epsilon$ | Regular or rational lang| Finite state automaton |


# BNF and EBNF

BNF 

Definition of context-free grammar A context-free grammar, also simply known as a free grammar or a type 2 or BNF (Backus Normal Form or Backus Naur Form) grammar, is of the form:

Where each rule in belongs to has a single non-terminal symbol from as its left-hand side:

EBNF 

Extended Backus Naur Form (EBNF) An Extended Backus Naur Form (EBNF) is a specific grammar that contains exactly one rule (i.e. one rule for each nonterminal); each rule has a different nonterminal on the left side and has a regular expression of alphabet on the right side, in which derived operators such as cross, power and optionality can also appear.



## Dyck Language 

Paradigma dei linguaggi ben parentizzati.

$$\begin{aligned}
& \Sigma=\left\{a, a^{\prime}, b, b^{\prime}\right\} \\
& S \rightarrow a S a^{\prime} S\left|b S b^{\prime} S\right| \varepsilon
\end{aligned}$$

Free but not regular 


Classificazione regole importanti 

Given a rule $A \rightarrow \alpha$ with $A \in V$ ($V$ are non-terminal symbols set) and $\alpha \in (V \cup \Sigma)^*$ (where $\Sigma$ is the set of terminal symbols of the grammar) we can classify the production itself according to many definitions. **Some** of the most important are: 

- Recursive rule on the left: the production is called a recursive rule on the left if its left part appears as a prefix of the right part $A \rightarrow A \delta$

- Recursive rule on the right The production is called a recursive rule on the right if its left part appears as a suffix of the right part $A \rightarrow \delta A$


There are many normal form; one of the most important is indispensable for the top-down parsers to be studied later in the course. This normal form is termed not left-recursive and it is characterized by the absence of left-recursive rules or derivations. 




## Linear language equations 

Linear languages can be represented as a set of linear equations, where the regular languages are the solutions. For a strictly right-linear grammar $G = \langle V, \Sigma, R, S \rangle$, where all terminal rules are empty, a string $x$ is in the language $L_A(G)$ if it meets certain criteria. Every rule can be transcribed into a linear equation that has as unknowns the languages generated from each non-terminal. The system of equations can be solved using substitution and the Arden Identity.