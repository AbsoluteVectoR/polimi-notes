# Inferenza parametrica

Dire qualcosa (FARE INFERENZA) sui parametri incogniti, usando
i dati (OSSERVAZIONI CAMPIONARIE).

## Stima puntuale 

Gli stimatori puntuali forniscono, per ogni realizzazione campionaria, un solo valore come “stima” del parametro incognito $\theta$ (o di una sua funzione $k(\theta)$). Lo stimatore è quindi una v.a. (o vettore aleatorio) e la stima è un numero (o un vettore di numeri).

## Distorsione di uno stimatore

Il **bias** è  la differenza tra il valore atteso dello stimatore e il parametro.
 $$bias = \mathbb E(\hat \theta ) -\theta$$
 
Quando uno stimatore **non** è distorto, allora si dice corretto.
  $$\mathbb E ( \hat \theta ) - \theta = 0 $$
Uno stimatore può essere anche **asintoticamente non distorto**. Cioè è distorto magari, ma il limite del valore atteso dello stimatore per n-osservazioni che tendono ad infinito è uguale al parametro.
 
### errore quadratico medio MSE 
 $$MSE(\hat \theta) = \mathbb{E}[(\hat \theta - \tau(\theta))^2]$$
 Ma anche (decomposizione): 
 $$MSE(\hat \theta)=Var(\hat \theta)+(bias(\hat \theta,\theta))^2$$
Preferire lo stimatore con errore quadratico medio più basso.
 
## Consistenza 

### Consistenza debole

Uno stimatore $\hat \theta$ si dice debolmente consistente quando: $$\lim _ {n \rightarrow \infty} P_{\theta}(|\hat \theta - \theta|>\epsilon)\rightarrow 0$$

### Consistenza in media 2
$$\lim _ {n \rightarrow \infty} \mathbb E _ \theta [(\hat \theta - \theta)^2]\rightarrow 0$$

Se  la successione di stimatori è consistente in media quadratica allora è anche debolmente consistente. 

### Consistenza forte
$$\mathbb P (\lim _{n \rightarrow \infty} \hat \theta =\theta)=1$$

# Metodi per la stima puntuale

## Principio di sostituzione 

 Stimo il mio parametro con la 'sua versione empirica'.
 mi baso sulla legge forte dei grandi numeri, e pongo quindi la mia media empirica uguale al parametro da stimare.
 Funzione cumulata empirica, e quindi anche di sopravvivenza.
 Metodo che funziona nel mondo della fantasia. 
 
## Principio dei momenti

Determinare il parametro $\theta$ univocamente dai momenti. Cioè cerchiamo il parametro che eguaglia i momenti 'teorici' con i momenti empirici. Ci troviamo quindi un sistema. 
 $$m_k = \frac{1}{n}\sum _{i+1}^n X_i^k$$
L'idea è simile al metodo di sostituzione.
 
## MLE: Maximum likelihood estimation
 
Criterio della massima verosimiglianza. Si basa su determinare il $\theta$ che con maggior probabilità ha generato i dati osservati. 
La funzione di verosimiglianza: $$L(\theta,x)=\prod^n _i f(x_i)$$
Ma usiamo quasi sempre la log-verosimiglianza. $l(\theta,x)=ln(L(\theta,x))$
La log-verosimiglianza ha gli stessi punti di massimo di L ma ha alcuni vantaggi: i prodotti diventano somme e gli esponenti diventano moltiplicazioni. 
$$l(\theta,x)=\sum ^n _i ln(f(x_i)$$

- asintoticamente non distorta
- consistenza in media quadratica 
- asintoticamente gaussiana

#### Principio d'invarianza funzionale per gli MLE
Se $\hat\Theta$ è lo stimatore di $\theta$ allora lo stimatore di massima verosimiglianza per $\alpha = g(\theta)$ è $\hat \alpha=g(\hat \theta)$

# Stima intervallare IC

Per quantificare il grado di precisione associato alla stima puntuale di un parametro $\theta$   si ricorre alla cosiddetta stima intervallare, cioè si costruisce un intervallo di valori in cui si ha una elevata fiducia che cada il valore incognito del parametro. Gli estremi dell'intverallo sono calcolati per mezzo del campione dei dati osservati. 

## Quantità pivotale

Sia Q la quantità pivotale per la costruzione di intervalli di confidenza. Allora: $$P_{\theta}(q_1<Q<q_2)$$
dove $q_1$ e $q_2$ dipendono dal livello di confidenza $\alpha$ ma non dal parametro $\theta$.
Ci sono intervalli bilateri e unilateri. 
IC più stretto implica più precisione. 

**Intervalli di confidenza per la media $\mu$, applicato nel caso di una popolazione normale:

- varianza $\sigma$ nota (Z):
$$P(\mu \in(\bar X _n \pm z_{1 - \alpha /2}\frac{\sigma}{\sqrt n}))=1-\alpha$$
- varianza $\sigma$ incognita (T):
 $$P(\mu \in(\bar X _n \pm t_{1 - \alpha /2}\frac{S_n}{\sqrt n}))=1-\alpha$$
*NB: in caso di campione numoroso, il caso della T di Student è approssimabile da una normale*

**Intervalli di confidenza per la varianza $\sigma$ , applicato nel caso di una popolazione normale:

-  media $\mu$ nota:
$$P(\frac{S^2(n)}{X^2_{1-\alpha/2,n}}<\sigma^2<\frac{S^2(n)}{X^2_{\alpha/2,n}})=1-\alpha/2$$
- media $\mu$ incognita :
$$P(\frac{S^2(n-1)}{X^2_{1-\alpha/2,n-1}}<\sigma^2<\frac{S^2(n-1)}{X^2_{\alpha/2,n-1}})=1-\alpha/2$$

**Proporzione $p$ di una popolazione bernoulliana**
$$P(\hat p - \frac{\sqrt{\hat p (1-\hat p)}}{n}z_{1-\alpha/2} < p < \hat p + \frac{\sqrt{\hat p (1-\hat p)}}{n}z_{1-\alpha/2})=1-\alpha$$

**Parametro $\lambda$ di una popolazione poissoniana**
$$P(\bar X - \frac{\sqrt{\bar X}}{n}z_{1-\alpha/2} < p < \bar X + \frac{\sqrt{\bar X}}{n}z_{1-\alpha/2})=1- \alpha$$

**Parametro $\lambda$ di una popolazione esponenziale**
$$P(\frac{1}{2n\bar X}X^2_{\alpha/2,2n}<\lambda<\frac{1}{2n \bar X}X^2_{\alpha /2,2n})$$
